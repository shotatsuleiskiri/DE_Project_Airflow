[2024-07-02T18:45:20.782+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.film_category manual__2024-07-02T18:45:18.498280+00:00 [queued]>
[2024-07-02T18:45:20.866+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.film_category manual__2024-07-02T18:45:18.498280+00:00 [queued]>
[2024-07-02T18:45:20.868+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-02T18:45:20.979+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): film_category> on 2024-07-02 18:45:18.498280+00:00
[2024-07-02T18:45:21.002+0000] {standard_task_runner.py:60} INFO - Started process 224 to run task
[2024-07-02T18:45:21.062+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'film_category', 'manual__2024-07-02T18:45:18.498280+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpdqe1a3in']
[2024-07-02T18:45:21.069+0000] {standard_task_runner.py:88} INFO - Job 34: Subtask film_category
[2024-07-02T18:45:21.208+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.film_category manual__2024-07-02T18:45:18.498280+00:00 [running]> on host 5b7251376729
[2024-07-02T18:45:21.437+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='film_category' AIRFLOW_CTX_EXECUTION_DATE='2024-07-02T18:45:18.498280+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-02T18:45:18.498280+00:00'
[2024-07-02T18:45:21.447+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-02T18:45:21.453+0000] {logging_mixin.py:188} INFO - table: film_category
[2024-07-02T18:45:21.455+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 type: FULL 
 schema: public 
 table:film_category
[2024-07-02T18:45:21.456+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 22, in process_table
    return  execute(table, stage, "FULL","public")
  File "/app/main.py", line 25, in execute
    SqlToStaging().create_full().some_function(stage, type, schema, table)
  File "/app/concretestage/SQLToStaging.py", line 25, in some_function
    sourceDF = getDF(yaml.getSourceDBName(), yaml.getTSourceTableName(),yaml.getSourceSchema())
  File "/app/myFramework/utils/readYaml.py", line 25, in getSourceDBName
    return self.getYaml()['SourceDBName']
  File "/app/myFramework/utils/readYaml.py", line 15, in getYaml
    with open(yaml_file_path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: '/app/conf/sqltostaging/FULL.yaml'
[2024-07-02T18:45:21.486+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=film_category, execution_date=20240702T184518, start_date=20240702T184520, end_date=20240702T184521
[2024-07-02T18:45:22.549+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 34 for task film_category ([Errno 2] No such file or directory: '/app/conf/sqltostaging/FULL.yaml'; 224)
[2024-07-02T18:45:22.638+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-02T18:45:23.176+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
