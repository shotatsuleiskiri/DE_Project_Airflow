[2024-07-10T19:19:12.751+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:19:12.772+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:19:12.775+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:19:12.817+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:19:12.836+0000] {standard_task_runner.py:60} INFO - Started process 90 to run task
[2024-07-10T19:19:12.847+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpvrl9ojkp']
[2024-07-10T19:19:12.860+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask staff
[2024-07-10T19:19:13.015+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 988357c0810b
[2024-07-10T19:19:14.555+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:19:14.562+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'SqlToStaging'
[2024-07-10T19:19:14.621+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)['tabletype'].values[0]
  File "/opt/airflow/dags/dag.py", line 30, in get_data_from_conf_table
    cur.execute(query)
AttributeError: 'psycopg2.extensions.connection' object has no attribute 'execute'
[2024-07-10T19:19:14.696+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T191912, end_date=20240710T191914
[2024-07-10T19:19:14.765+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 6 for task staff ('psycopg2.extensions.connection' object has no attribute 'execute'; 90)
[2024-07-10T19:19:14.799+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:19:14.878+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:24:52.100+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:24:52.118+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:24:52.118+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:24:52.155+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:24:52.168+0000] {standard_task_runner.py:60} INFO - Started process 94 to run task
[2024-07-10T19:24:52.179+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp3grf7etl']
[2024-07-10T19:24:52.189+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask staff
[2024-07-10T19:24:52.369+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 1dd842c603c2
[2024-07-10T19:24:53.665+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:24:53.671+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'SqlToStaging'
[2024-07-10T19:24:53.700+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)['tabletype'].values[0]
  File "/opt/airflow/dags/dag.py", line 34, in get_data_from_conf_table
    df.columns = [desc[0] for desc in cur.description]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 6002, in __setattr__
    return object.__setattr__(self, name, value)
  File "pandas/_libs/properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 730, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py", line 225, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/base.py", line 70, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 15 elements
[2024-07-10T19:24:53.717+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T192452, end_date=20240710T192453
[2024-07-10T19:24:53.742+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 12 for task staff (Length mismatch: Expected axis has 0 elements, new values have 15 elements; 94)
[2024-07-10T19:24:53.811+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:24:53.892+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:33:52.650+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:33:52.658+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:33:52.660+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:33:52.690+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:33:52.695+0000] {standard_task_runner.py:60} INFO - Started process 89 to run task
[2024-07-10T19:33:52.703+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpm9dozss0']
[2024-07-10T19:33:52.708+0000] {standard_task_runner.py:88} INFO - Job 4: Subtask staff
[2024-07-10T19:33:52.846+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host a0982d156a38
[2024-07-10T19:33:53.986+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:33:53.996+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'SqlToStaging'
[2024-07-10T19:33:54.107+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)
  File "/opt/airflow/dags/dag.py", line 34, in get_data_from_conf_table
    df.columns = [desc[0] for desc in cur.description]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 6002, in __setattr__
    return object.__setattr__(self, name, value)
  File "pandas/_libs/properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 730, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py", line 225, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/base.py", line 70, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 15 elements
[2024-07-10T19:33:54.165+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T193352, end_date=20240710T193354
[2024-07-10T19:33:54.187+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 4 for task staff (Length mismatch: Expected axis has 0 elements, new values have 15 elements; 89)
[2024-07-10T19:33:54.258+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:33:54.294+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:37:48.045+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:37:48.103+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:37:48.109+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:37:48.161+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:37:48.171+0000] {standard_task_runner.py:60} INFO - Started process 237 to run task
[2024-07-10T19:37:48.178+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpscmejyuc']
[2024-07-10T19:37:48.191+0000] {standard_task_runner.py:88} INFO - Job 35: Subtask staff
[2024-07-10T19:37:48.324+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host a0982d156a38
[2024-07-10T19:37:48.534+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:37:48.538+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T19:37:49.593+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   9  staff  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:37:49.628+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T19:37:49.639+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:37:49.643+0000] {logging_mixin.py:188} INFO - table: staff
[2024-07-10T19:37:49.650+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:staff
[2024-07-10T19:37:49.651+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:37:49.676+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T193748, end_date=20240710T193749
[2024-07-10T19:37:49.757+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:37:49.795+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:39:58.223+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:39:58.249+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:39:58.253+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:39:58.329+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:39:58.364+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpjhxwwg8g']
[2024-07-10T19:39:58.372+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask staff
[2024-07-10T19:39:58.354+0000] {standard_task_runner.py:60} INFO - Started process 96 to run task
[2024-07-10T19:39:58.626+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 4118dead3d7f
[2024-07-10T19:39:59.899+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:39:59.902+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T19:39:59.929+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   9  staff  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:39:59.941+0000] {logging_mixin.py:188} INFO - full
[2024-07-10T19:39:59.942+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:39:59.945+0000] {logging_mixin.py:188} INFO - table: staff
[2024-07-10T19:39:59.946+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:staff
[2024-07-10T19:39:59.948+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:39:59.972+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T193958, end_date=20240710T193959
[2024-07-10T19:39:59.997+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:40:00.080+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:44:03.284+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:44:03.331+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:44:03.335+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:44:03.413+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:44:03.445+0000] {standard_task_runner.py:60} INFO - Started process 102 to run task
[2024-07-10T19:44:03.467+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpfx7wdz2e']
[2024-07-10T19:44:03.480+0000] {standard_task_runner.py:88} INFO - Job 17: Subtask staff
[2024-07-10T19:44:03.630+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host a383c1e8c871
[2024-07-10T19:44:05.053+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:44:05.062+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T19:44:05.107+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   9  staff  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:44:05.111+0000] {logging_mixin.py:188} INFO - full
[2024-07-10T19:44:05.113+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:44:05.115+0000] {logging_mixin.py:188} INFO - table: staff
[2024-07-10T19:44:05.118+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:staff
[2024-07-10T19:44:05.120+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:44:05.130+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T194403, end_date=20240710T194405
[2024-07-10T19:44:05.156+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:44:05.179+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:53:56.931+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:53:56.963+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:53:56.966+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:53:57.008+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:53:57.018+0000] {standard_task_runner.py:60} INFO - Started process 94 to run task
[2024-07-10T19:53:57.024+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpni1spa18']
[2024-07-10T19:53:57.048+0000] {standard_task_runner.py:88} INFO - Job 7: Subtask staff
[2024-07-10T19:53:57.219+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host c340805483c7
[2024-07-10T19:53:57.930+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:53:58.082+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:53:58.121+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T195356, end_date=20240710T195358
[2024-07-10T19:53:58.213+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:53:58.317+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:56:46.689+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:56:46.714+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:56:46.721+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:56:46.760+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:56:46.780+0000] {standard_task_runner.py:60} INFO - Started process 99 to run task
[2024-07-10T19:56:46.787+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpw21beg5w']
[2024-07-10T19:56:46.802+0000] {standard_task_runner.py:88} INFO - Job 14: Subtask staff
[2024-07-10T19:56:46.959+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host eb5f087f7265
[2024-07-10T19:56:47.852+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:56:47.955+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:56:48.000+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T195646, end_date=20240710T195648
[2024-07-10T19:56:48.095+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:56:48.175+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:00:56.744+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:00:56.785+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:00:56.787+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:00:56.835+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:00:56.847+0000] {standard_task_runner.py:60} INFO - Started process 96 to run task
[2024-07-10T20:00:56.871+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpyk0uhmxt']
[2024-07-10T20:00:56.889+0000] {standard_task_runner.py:88} INFO - Job 11: Subtask staff
[2024-07-10T20:00:57.210+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host c8649e4aae44
[2024-07-10T20:01:01.386+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:01:01.467+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:01:01.671+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:01:01.723+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:01:01.805+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T200056, end_date=20240710T200101
[2024-07-10T20:01:02.304+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 11 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 96)
[2024-07-10T20:01:02.381+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:01:02.626+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:05:21.156+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:05:21.179+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:05:21.184+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:05:21.205+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:05:21.215+0000] {standard_task_runner.py:60} INFO - Started process 89 to run task
[2024-07-10T20:05:21.227+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpns_rk_0w']
[2024-07-10T20:05:21.233+0000] {standard_task_runner.py:88} INFO - Job 7: Subtask staff
[2024-07-10T20:05:21.415+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 3f026d601c5c
[2024-07-10T20:05:22.356+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:05:22.446+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:05:22.598+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:05:22.602+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:05:22.651+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T200521, end_date=20240710T200522
[2024-07-10T20:05:22.661+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 89)
[2024-07-10T20:05:22.705+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:05:22.798+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:09:18.287+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:09:18.309+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:09:18.311+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:09:18.414+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:09:18.460+0000] {standard_task_runner.py:60} INFO - Started process 93 to run task
[2024-07-10T20:09:18.468+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp92f92fy3']
[2024-07-10T20:09:18.482+0000] {standard_task_runner.py:88} INFO - Job 7: Subtask staff
[2024-07-10T20:09:18.657+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 61a58fe9b448
[2024-07-10T20:09:19.700+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:09:19.820+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:09:19.990+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:09:20.003+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:09:20.031+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T200918, end_date=20240710T200920
[2024-07-10T20:09:20.055+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 93)
[2024-07-10T20:09:20.113+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:09:20.175+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:15:06.625+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:15:06.634+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:15:06.639+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:15:06.714+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:15:06.728+0000] {standard_task_runner.py:60} INFO - Started process 97 to run task
[2024-07-10T20:15:06.754+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp6iv65owe']
[2024-07-10T20:15:06.792+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask staff
[2024-07-10T20:15:06.981+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host c782b552e7b5
[2024-07-10T20:15:08.458+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:15:08.488+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:15:08.529+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:15:08.532+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:15:08.552+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T201506, end_date=20240710T201508
[2024-07-10T20:15:08.613+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 8 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 97)
[2024-07-10T20:15:08.670+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:15:08.705+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:19:53.602+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:19:53.624+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:19:53.626+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:19:53.659+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:19:53.667+0000] {standard_task_runner.py:60} INFO - Started process 98 to run task
[2024-07-10T20:19:53.690+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpate8h9dz']
[2024-07-10T20:19:53.705+0000] {standard_task_runner.py:88} INFO - Job 16: Subtask staff
[2024-07-10T20:19:53.900+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host dcd5a91c9a96
[2024-07-10T20:19:55.088+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:19:55.121+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:19:55.156+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:19:55.157+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:19:55.176+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T201953, end_date=20240710T201955
[2024-07-10T20:19:55.185+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 16 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 98)
[2024-07-10T20:19:55.214+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:19:55.258+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:25:52.168+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:25:52.211+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:25:52.218+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:25:52.252+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:25:52.273+0000] {standard_task_runner.py:60} INFO - Started process 132 to run task
[2024-07-10T20:25:52.325+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpbb7m5zf9']
[2024-07-10T20:25:52.362+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask staff
[2024-07-10T20:25:52.551+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host d72f5bf26a9d
[2024-07-10T20:25:53.736+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:25:53.841+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:25:53.923+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:25:53.926+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:25:53.941+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T202552, end_date=20240710T202553
[2024-07-10T20:25:53.972+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 15 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 132)
[2024-07-10T20:25:53.989+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:25:54.039+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:33:41.841+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:33:41.871+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:33:41.878+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:33:41.908+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:33:41.920+0000] {standard_task_runner.py:60} INFO - Started process 99 to run task
[2024-07-10T20:33:41.953+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmph9zzdbw0']
[2024-07-10T20:33:41.975+0000] {standard_task_runner.py:88} INFO - Job 17: Subtask staff
[2024-07-10T20:33:42.137+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host d0a0151057b2
[2024-07-10T20:33:43.360+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:33:43.400+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:33:43.453+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:33:43.457+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:33:43.485+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T203341, end_date=20240710T203343
[2024-07-10T20:33:43.530+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 17 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 99)
[2024-07-10T20:33:43.590+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:33:43.637+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:36:57.498+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:36:57.509+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:36:57.514+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:36:57.555+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:36:57.571+0000] {standard_task_runner.py:60} INFO - Started process 97 to run task
[2024-07-10T20:36:57.605+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpzikjlrgt']
[2024-07-10T20:36:57.667+0000] {standard_task_runner.py:88} INFO - Job 10: Subtask staff
[2024-07-10T20:36:57.847+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host dca83dd4e715
[2024-07-10T20:36:59.199+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:36:59.235+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:36:59.434+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:36:59.435+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:36:59.450+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T203657, end_date=20240710T203659
[2024-07-10T20:36:59.554+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 10 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 97)
[2024-07-10T20:36:59.633+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:36:59.656+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:40:13.949+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:40:13.974+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:40:13.980+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:40:14.028+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): staff> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:40:14.057+0000] {standard_task_runner.py:60} INFO - Started process 94 to run task
[2024-07-10T20:40:14.070+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'staff', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpl48h8lp1']
[2024-07-10T20:40:14.078+0000] {standard_task_runner.py:88} INFO - Job 7: Subtask staff
[2024-07-10T20:40:14.253+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.staff scheduled__2024-07-09T00:00:00+00:00 [running]> on host 2bc01acfbd3e
[2024-07-10T20:40:15.013+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='staff' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:40:15.076+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'staff' and Stage = 'sqltostaging'
[2024-07-10T20:40:15.213+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   9           staff    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:40:15.221+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:40:15.266+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=staff, execution_date=20240709T000000, start_date=20240710T204013, end_date=20240710T204015
[2024-07-10T20:40:15.309+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task staff (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 94)
[2024-07-10T20:40:15.374+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:40:15.457+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
