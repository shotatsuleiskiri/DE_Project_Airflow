[2024-07-10T19:19:12.760+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:19:12.795+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:19:12.806+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:19:12.832+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:19:12.859+0000] {standard_task_runner.py:60} INFO - Started process 92 to run task
[2024-07-10T19:19:12.862+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpuqk3jxku']
[2024-07-10T19:19:12.880+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask store
[2024-07-10T19:19:13.058+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 988357c0810b
[2024-07-10T19:19:14.562+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:19:14.566+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'SqlToStaging'
[2024-07-10T19:19:14.626+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)['tabletype'].values[0]
  File "/opt/airflow/dags/dag.py", line 30, in get_data_from_conf_table
    cur.execute(query)
AttributeError: 'psycopg2.extensions.connection' object has no attribute 'execute'
[2024-07-10T19:19:14.661+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=store, execution_date=20240709T000000, start_date=20240710T191912, end_date=20240710T191914
[2024-07-10T19:19:14.692+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 9 for task store ('psycopg2.extensions.connection' object has no attribute 'execute'; 92)
[2024-07-10T19:19:14.735+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:19:14.817+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:24:52.049+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:24:52.078+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:24:52.084+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:24:52.139+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:24:52.148+0000] {standard_task_runner.py:60} INFO - Started process 93 to run task
[2024-07-10T19:24:52.166+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_ppv86zg']
[2024-07-10T19:24:52.174+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask store
[2024-07-10T19:24:52.391+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 1dd842c603c2
[2024-07-10T19:24:53.541+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:24:53.553+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'SqlToStaging'
[2024-07-10T19:24:53.617+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)['tabletype'].values[0]
  File "/opt/airflow/dags/dag.py", line 34, in get_data_from_conf_table
    df.columns = [desc[0] for desc in cur.description]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 6002, in __setattr__
    return object.__setattr__(self, name, value)
  File "pandas/_libs/properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 730, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py", line 225, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/base.py", line 70, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 15 elements
[2024-07-10T19:24:53.658+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=store, execution_date=20240709T000000, start_date=20240710T192452, end_date=20240710T192453
[2024-07-10T19:24:53.678+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 9 for task store (Length mismatch: Expected axis has 0 elements, new values have 15 elements; 93)
[2024-07-10T19:24:53.718+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:24:53.781+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:33:52.725+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:33:52.750+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:33:52.753+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:33:52.790+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:33:52.815+0000] {standard_task_runner.py:60} INFO - Started process 95 to run task
[2024-07-10T19:33:52.828+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'SqlToStaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpg290g_zv']
[2024-07-10T19:33:52.842+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask store
[2024-07-10T19:33:52.978+0000] {task_command.py:423} INFO - Running <TaskInstance: SqlToStaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host a0982d156a38
[2024-07-10T19:33:54.202+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='SqlToStaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:33:54.204+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'SqlToStaging'
[2024-07-10T19:33:54.224+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 41, in process_table
    tabletype = get_data_from_conf_table(table,stage)
  File "/opt/airflow/dags/dag.py", line 34, in get_data_from_conf_table
    df.columns = [desc[0] for desc in cur.description]
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 6002, in __setattr__
    return object.__setattr__(self, name, value)
  File "pandas/_libs/properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 730, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py", line 225, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/base.py", line 70, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 15 elements
[2024-07-10T19:33:54.234+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=SqlToStaging, task_id=store, execution_date=20240709T000000, start_date=20240710T193352, end_date=20240710T193354
[2024-07-10T19:33:54.243+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 9 for task store (Length mismatch: Expected axis has 0 elements, new values have 15 elements; 95)
[2024-07-10T19:33:54.286+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T19:33:54.338+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:37:48.221+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:37:48.241+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:37:48.245+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:37:48.281+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:37:48.290+0000] {standard_task_runner.py:60} INFO - Started process 243 to run task
[2024-07-10T19:37:48.313+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpecama8dh']
[2024-07-10T19:37:48.324+0000] {standard_task_runner.py:88} INFO - Job 42: Subtask store
[2024-07-10T19:37:48.455+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host a0982d156a38
[2024-07-10T19:37:48.659+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:37:48.669+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T19:37:49.789+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   1  store  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:37:49.805+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T19:37:49.805+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:37:49.806+0000] {logging_mixin.py:188} INFO - table: store
[2024-07-10T19:37:49.808+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:store
[2024-07-10T19:37:49.810+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:37:49.828+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T193748, end_date=20240710T193749
[2024-07-10T19:37:49.875+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:37:49.900+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:39:58.255+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:39:58.273+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:39:58.276+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:39:58.319+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:39:58.348+0000] {standard_task_runner.py:60} INFO - Started process 94 to run task
[2024-07-10T19:39:58.350+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpvd7ez046']
[2024-07-10T19:39:58.361+0000] {standard_task_runner.py:88} INFO - Job 10: Subtask store
[2024-07-10T19:39:58.594+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 4118dead3d7f
[2024-07-10T19:40:00.090+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:40:00.105+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T19:40:00.135+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   1  store  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:40:00.140+0000] {logging_mixin.py:188} INFO - full
[2024-07-10T19:40:00.140+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:40:00.141+0000] {logging_mixin.py:188} INFO - table: store
[2024-07-10T19:40:00.143+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:store
[2024-07-10T19:40:00.144+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:40:00.153+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T193958, end_date=20240710T194000
[2024-07-10T19:40:00.179+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:40:00.192+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:44:02.991+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:44:03.003+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:44:03.005+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:44:03.047+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:44:03.061+0000] {standard_task_runner.py:60} INFO - Started process 90 to run task
[2024-07-10T19:44:03.067+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpho29bhfj']
[2024-07-10T19:44:03.086+0000] {standard_task_runner.py:88} INFO - Job 6: Subtask store
[2024-07-10T19:44:03.412+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host a383c1e8c871
[2024-07-10T19:44:04.698+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:44:04.706+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T19:44:04.791+0000] {logging_mixin.py:188} INFO -    0      1          2       3     4   ...    10    11    12            13    14
0   1  store  dvdrental  public  full  ...  None  None  None  sqltostaging  None

[1 rows x 15 columns]
[2024-07-10T19:44:04.798+0000] {logging_mixin.py:188} INFO - full
[2024-07-10T19:44:04.814+0000] {logging_mixin.py:188} INFO - dvtobv :dag_id
[2024-07-10T19:44:04.843+0000] {logging_mixin.py:188} INFO - table: store
[2024-07-10T19:44:04.867+0000] {logging_mixin.py:188} INFO - 
 stage: sqltostaging 
 table:store
[2024-07-10T19:44:04.867+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:44:04.881+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T194402, end_date=20240710T194404
[2024-07-10T19:44:04.963+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:44:05.067+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:53:56.946+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:53:56.972+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:53:56.978+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:53:57.008+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:53:57.014+0000] {standard_task_runner.py:60} INFO - Started process 93 to run task
[2024-07-10T19:53:57.024+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp84dmqfdw']
[2024-07-10T19:53:57.046+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask store
[2024-07-10T19:53:57.151+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host c340805483c7
[2024-07-10T19:53:58.255+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:53:58.285+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:53:58.297+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T195356, end_date=20240710T195358
[2024-07-10T19:53:58.376+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:53:58.428+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T19:56:46.618+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:56:46.639+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T19:56:46.644+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T19:56:46.676+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T19:56:46.701+0000] {standard_task_runner.py:60} INFO - Started process 92 to run task
[2024-07-10T19:56:46.719+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp2w15jcc5']
[2024-07-10T19:56:46.728+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask store
[2024-07-10T19:56:46.911+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host eb5f087f7265
[2024-07-10T19:56:47.553+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T19:56:47.685+0000] {python.py:202} INFO - Done. Returned value was: None
[2024-07-10T19:56:47.706+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T195646, end_date=20240710T195647
[2024-07-10T19:56:47.771+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-10T19:56:47.836+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:00:57.001+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:00:57.044+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:00:57.048+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:00:57.106+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:00:57.137+0000] {standard_task_runner.py:60} INFO - Started process 100 to run task
[2024-07-10T20:00:57.148+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp_bsawe6o']
[2024-07-10T20:00:57.154+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask store
[2024-07-10T20:00:57.388+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host c8649e4aae44
[2024-07-10T20:01:01.280+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:01:01.352+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:01:01.626+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:01:01.632+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:01:01.670+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T200057, end_date=20240710T200101
[2024-07-10T20:01:01.885+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 15 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 100)
[2024-07-10T20:01:01.972+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:01:02.492+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:05:21.202+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:05:21.223+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:05:21.231+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:05:21.272+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:05:21.288+0000] {standard_task_runner.py:60} INFO - Started process 98 to run task
[2024-07-10T20:05:21.312+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpp_b9fjqz']
[2024-07-10T20:05:21.322+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask store
[2024-07-10T20:05:21.473+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 3f026d601c5c
[2024-07-10T20:05:22.576+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:05:22.631+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:05:22.679+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:05:22.687+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:05:22.705+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T200521, end_date=20240710T200522
[2024-07-10T20:05:22.748+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 15 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 98)
[2024-07-10T20:05:22.786+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:05:22.839+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:09:18.959+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:09:19.015+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:09:19.033+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:09:19.110+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:09:19.137+0000] {standard_task_runner.py:60} INFO - Started process 103 to run task
[2024-07-10T20:09:19.314+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp3j5w_k42']
[2024-07-10T20:09:19.395+0000] {standard_task_runner.py:88} INFO - Job 17: Subtask store
[2024-07-10T20:09:19.698+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 61a58fe9b448
[2024-07-10T20:09:20.293+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:09:20.328+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:09:20.369+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:09:20.372+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:09:20.398+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T200918, end_date=20240710T200920
[2024-07-10T20:09:20.414+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 17 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 103)
[2024-07-10T20:09:20.438+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:09:20.501+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:15:06.661+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:15:06.674+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:15:06.683+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:15:06.724+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:15:06.751+0000] {standard_task_runner.py:60} INFO - Started process 100 to run task
[2024-07-10T20:15:06.780+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmppe8nju0n']
[2024-07-10T20:15:06.789+0000] {standard_task_runner.py:88} INFO - Job 10: Subtask store
[2024-07-10T20:15:06.949+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host c782b552e7b5
[2024-07-10T20:15:08.315+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:15:08.350+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:15:08.455+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:15:08.460+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:15:08.476+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T201506, end_date=20240710T201508
[2024-07-10T20:15:08.500+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 10 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 100)
[2024-07-10T20:15:08.542+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:15:08.633+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:19:53.465+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:19:53.518+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:19:53.524+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:19:53.551+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:19:53.566+0000] {standard_task_runner.py:60} INFO - Started process 92 to run task
[2024-07-10T20:19:53.591+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpzpqijpm0']
[2024-07-10T20:19:53.628+0000] {standard_task_runner.py:88} INFO - Job 7: Subtask store
[2024-07-10T20:19:53.919+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host dcd5a91c9a96
[2024-07-10T20:19:54.984+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:19:55.017+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:19:55.074+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:19:55.081+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:19:55.098+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T201953, end_date=20240710T201955
[2024-07-10T20:19:55.118+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 7 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 92)
[2024-07-10T20:19:55.163+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:19:55.206+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:25:52.151+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:25:52.171+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:25:52.181+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:25:52.228+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:25:52.245+0000] {standard_task_runner.py:60} INFO - Started process 127 to run task
[2024-07-10T20:25:52.251+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpr1go1w_1']
[2024-07-10T20:25:52.264+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask store
[2024-07-10T20:25:52.516+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host d72f5bf26a9d
[2024-07-10T20:25:53.529+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:25:53.668+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:25:53.808+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:25:53.819+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:25:53.844+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T202552, end_date=20240710T202553
[2024-07-10T20:25:53.884+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 12 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 127)
[2024-07-10T20:25:53.934+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:25:53.994+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:33:41.866+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:33:41.891+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:33:41.901+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:33:41.940+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:33:41.955+0000] {standard_task_runner.py:60} INFO - Started process 102 to run task
[2024-07-10T20:33:41.969+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpmjjujjib']
[2024-07-10T20:33:41.981+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask store
[2024-07-10T20:33:42.152+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host d0a0151057b2
[2024-07-10T20:33:43.415+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:33:43.482+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:33:43.609+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:33:43.612+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:33:43.639+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T203341, end_date=20240710T203343
[2024-07-10T20:33:43.648+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 15 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 102)
[2024-07-10T20:33:43.699+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:33:43.730+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:36:57.493+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:36:57.508+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:36:57.510+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:36:57.550+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:36:57.556+0000] {standard_task_runner.py:60} INFO - Started process 94 to run task
[2024-07-10T20:36:57.565+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmp7n63eygo']
[2024-07-10T20:36:57.579+0000] {standard_task_runner.py:88} INFO - Job 11: Subtask store
[2024-07-10T20:36:57.841+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host dca83dd4e715
[2024-07-10T20:36:59.128+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:36:59.257+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:36:59.415+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:36:59.426+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:36:59.452+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T203657, end_date=20240710T203659
[2024-07-10T20:36:59.666+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 11 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 94)
[2024-07-10T20:36:59.713+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:36:59.728+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-10T20:40:14.042+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:40:14.058+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [queued]>
[2024-07-10T20:40:14.069+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-10T20:40:14.110+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): store> on 2024-07-09 00:00:00+00:00
[2024-07-10T20:40:14.123+0000] {standard_task_runner.py:60} INFO - Started process 99 to run task
[2024-07-10T20:40:14.142+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'sqltostaging', 'store', 'scheduled__2024-07-09T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpai4ii2_c']
[2024-07-10T20:40:14.155+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask store
[2024-07-10T20:40:14.321+0000] {task_command.py:423} INFO - Running <TaskInstance: sqltostaging.store scheduled__2024-07-09T00:00:00+00:00 [running]> on host 2bc01acfbd3e
[2024-07-10T20:40:15.494+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='sqltostaging' AIRFLOW_CTX_TASK_ID='store' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-09T00:00:00+00:00'
[2024-07-10T20:40:15.532+0000] {logging_mixin.py:188} INFO - select *  from etlconf.Etl_Process_Mapping where SourceTableName = 'store' and Stage = 'sqltostaging'
[2024-07-10T20:40:15.580+0000] {logging_mixin.py:188} INFO -    id sourcetablename sourcedbname  ...  code         stage last_run_date
0   1           store    dvdrental  ...  None  sqltostaging          None

[1 rows x 15 columns]
[2024-07-10T20:40:15.583+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag.py", line 44, in process_table
    return  execute(table, stage, tabletype)
  File "/app/main.py", line 26, in execute
    SqlToStaging().create_full().some_function(table, stage)
  File "/app/concretestage/SQLToStaging.py", line 38, in some_function
    sourceDF = getDF(sourcedbname,sourcetablename , sourceschema)
TypeError: getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'
[2024-07-10T20:40:15.603+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=sqltostaging, task_id=store, execution_date=20240709T000000, start_date=20240710T204014, end_date=20240710T204015
[2024-07-10T20:40:15.612+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 9 for task store (getDF() missing 3 required positional arguments: 'filterColumn', 'dateFrom', and 'dateTo'; 99)
[2024-07-10T20:40:15.646+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-10T20:40:15.663+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
